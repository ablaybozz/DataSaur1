{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKDCQgH7UMrW"
      },
      "source": [
        "# DataSaur Case 3\n",
        "---\n",
        "\n",
        "Due date: **October 15th 2023, 14.00**\n",
        "\n",
        "## Description\n",
        "---\n",
        "Необходимо обучить модель для выявления поддельных фотографий автотранспорта, так как люди ежегодно пытаются избежать технического осмотра, применяя методы подделки, такие как фотошоп и другие.\n",
        "\n",
        "В данной задаче по бинарной классификации \"0\" являются правильным фото автотранспорта, \"1\" являются фиктивными фото (снятые с экрана монитора, фотошопом и тд.)\n",
        "\n",
        "В папке \"фиктивные\" вы можете заметить что фото сами также делятся на подклассы. Все они будут являться \"1\" для этой задачи. Если ваша модель также правильно будет определять подклассы фиктивных фото, покажите работу модели во время защиты решения задач. За это будет отдельный бонус.\n",
        "\n",
        "На презентацию кода пройдут топ 7 работ по итогу данного соревнования\n",
        "\n",
        "# Dataset Preparation\n",
        "___\n",
        "\n",
        "1.  Download `techosmotr.zip` from the course website to your local machine.\n",
        "2.  Go to Google Drive and upload the folder.\n",
        "3.  Run the code block below. It will ask for permission to mount your Google Drive so this colab can access it. Paste the authorization code into the box as requested."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL0F8_fvxE6G",
        "outputId": "1debe4a6-708e-44fb-e787-e8c57413bb66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/techosmotr/techosmotr\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd  /content/drive/'My Drive'/techosmotr/techosmotr/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make sure you have all libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "from torchvision import models\n",
        "import pickle\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea3RlLSGVRRm"
      },
      "source": [
        "# Dataloader for Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ulWM9WoVxNZi"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "momentum = 0.9\n",
        "lr = 0.0075\n",
        "epochs = 20\n",
        "log_interval = 100\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, cat_dir, not_cat_dirs, transform=None):\n",
        "        # Load cat images\n",
        "        self.cat_images = [os.path.join(cat_dir, img) for img in os.listdir(cat_dir)]\n",
        "\n",
        "        # Load not-cat images from multiple directories\n",
        "        self.not_cat_images = []\n",
        "        for not_cat_dir in not_cat_dirs:\n",
        "            self.not_cat_images.extend([os.path.join(not_cat_dir, img) for img in os.listdir(not_cat_dir)])\n",
        "\n",
        "        # Combining and labeling\n",
        "        self.all_images = self.cat_images + self.not_cat_images\n",
        "        self.labels = torch.tensor([0] * len(self.cat_images) + [1] * len(self.not_cat_images) )  # Update labels accordingly\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.all_images[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load train data\n",
        "skip this section if you dont want to train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize dataset\n",
        "cat_dir = \"train/pravilniye(correct)/0-correct\"\n",
        "not_cat_dirs = [\"train/fictivniye(fictitious)/1-not-on-the-brake-stand\", \"train/fictivniye(fictitious)/2-from-the-screen\", \"train/fictivniye(fictitious)/3-from-the-screen+photoshop\", \"train/fictivniye(fictitious)/4-photoshop\"]\n",
        "\n",
        "dataset = CustomImageDataset(cat_dir=cat_dir, not_cat_dirs=not_cat_dirs, transform=transform)\n",
        "\n",
        "# Split the dataset into train and validation subsets\n",
        "train_size = int(0.8 * len(dataset))  # 80% for training\n",
        "val_size = len(dataset) - train_size   # 20% for validation\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "val_loader  = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcVzXyCWV4R3"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KWX1k5lZx1B3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "nclasses = 2  # Assuming binary classification\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Load a pre-trained ResNet model and extract features\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        # Remove the last fully connected layer (classification layer)\n",
        "        self.features = nn.Sequential(*list(self.resnet.children())[:-1])\n",
        "\n",
        "        # Define new classification layers\n",
        "        self.fc1 = nn.Linear(512, 256)  # For resnet18, resnet34\n",
        "        # If you use resnet50, resnet101, or resnet152, use the line below instead:\n",
        "        # self.fc1 = nn.Linear(2048, 256)\n",
        "\n",
        "        self.fc1_norm = nn.BatchNorm1d(256)\n",
        "        self.fc1_drop = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, nclasses)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features using ResNet\n",
        "        x = self.features(x)\n",
        "        # Flatten the output from the ResNet feature extractor\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Forward through the custom classification layer\n",
        "        x = self.fc1_norm(F.relu(self.fc1(x)))\n",
        "        x = self.fc1_drop(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exQY_n5qWC_M"
      },
      "source": [
        "# Training\n",
        "If you dont want to wait for the model to train (takes couple of hours)<br>\n",
        "You can skip this part and jump directly to Evaluate and Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRjm-15Yx8Tg",
        "outputId": "283fdc64-c8d9-433b-9178-1a9cb1843ccd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 264MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda:0 device.\n",
            "Train Epoch: 1 [0/5926 (0%)]\tLoss: 0.931806\n"
          ]
        }
      ],
      "source": [
        "model = Net()\n",
        "\n",
        "# Check if GPU is available and if not, use CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using {device} device.')\n",
        "\n",
        "# Move the model to the device (GPU if available)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Move data and target to GPU if available\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def validation():\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            # Move data and target to GPU if available\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            validation_loss += F.nll_loss(output, target, reduction=\"sum\").item() # sum up batch loss\n",
        "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    validation_loss /= len(val_loader.dataset)\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        validation_loss, correct, len(val_loader.dataset),\n",
        "        100. * correct / len(val_loader.dataset)))\n",
        "\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    validation()\n",
        "    model_file = 'model_' + str(epoch) + '.pth'\n",
        "    torch.save(model.state_dict(), model_file)\n",
        "    print('\\nSaved model to ' + model_file + '.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQPmLXuDWIb4"
      },
      "source": [
        "# Evaluate and Submission File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmYZ9AccyA-m",
        "outputId": "16bb5033-a181-45c1-fda6-61484101368e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Written to csv file predictions.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class TestImageDataset(Dataset):\n",
        "    def __init__(self, dir, transform=None):\n",
        "        self.image_files = [os.path.join(dir, f) for f in os.listdir(dir)]\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_files[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, os.path.basename(image_path)  # return image and filename\n",
        "\n",
        "# Define your model architecture and replace the checkpoint path\n",
        "model = Net()  # Your model class here\n",
        "model.load_state_dict(torch.load(\"model_8.pth\")) ### select best model with best validation score\n",
        "model.eval()\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Test dataset and loader\n",
        "test_dir = \"test\"\n",
        "test_dataset = TestImageDataset(dir=test_dir, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Collecting predictions and file names\n",
        "dataframe_dict = {\"file_index\" : [], \"class\": []}\n",
        "\n",
        "# Prediction\n",
        "with torch.no_grad():\n",
        "    for images, filenames in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Replace with your prediction logic if not a simple argmax\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        dataframe_dict['file_index'].extend(filenames)\n",
        "        dataframe_dict['class'].extend(preds.cpu().numpy())\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(data=dataframe_dict)\n",
        "# Remove .jpeg and convert filenames to integer indices\n",
        "df['file_index'] = df['file_index'].apply(lambda x: int(x.replace(\".jpeg\", \"\")))\n",
        "df.to_csv(\"predictions.csv\", index=False)\n",
        "print(\"Written to csv file predictions.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
